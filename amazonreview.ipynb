{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6cfa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidVectorizer\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2bc1400",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Downloads/extract_reviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f709093c43c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/extract_reviews.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Downloads/extract_reviews.csv'"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_csv('Downloads/extract_reviews.csv')\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2e8d16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b0ab0cf38406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mreviews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomment\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reviews' is not defined"
     ]
    }
   ],
   "source": [
    "reviews = [comment.strip() for comment in reviews.comment]\n",
    "reviews = [comment for comment in reviews if comment]\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0857474b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reviews'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_text = ''.join('reviews')\n",
    "reviews_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411163e0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the first two maketrans arguments must have equal length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8050fd3ff1ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnopunctext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreviews_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnopunctext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: the first two maketrans arguments must have equal length"
     ]
    }
   ],
   "source": [
    "nopunctext = reviews_text.translate(str.maketrans('','',string.punctuation))\n",
    "nopunctext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c20774",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nopunctext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dfbd36ba7d70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtexttokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnopunctext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexttokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nopunctext' is not defined"
     ]
    }
   ],
   "source": [
    "texttokens = word_tokenize(nopunctext)\n",
    "print(texttokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb46a022",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texttokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-91ce5e420cd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mswlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'I'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'The'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'It'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmystopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnostoptokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexttokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmystopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnostoptokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texttokens' is not defined"
     ]
    }
   ],
   "source": [
    "mystopwords = stopwords.words('english')\n",
    "swlist = ['I','The','It','A']\n",
    "mystopwords.extend(swlist)\n",
    "nostoptokens = [word for word in texttokens if not word in mystopwords]\n",
    "print(nostoptokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf4dba0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nostoptokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8d90ae604bd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlowerwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnostoptokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowerwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nostoptokens' is not defined"
     ]
    }
   ],
   "source": [
    "lowerwords = [comment.lower() for comment in nostoptokens]\n",
    "print(lowerwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf089720",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lowerwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e7956c282ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstemmedtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlowerwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstemmedtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lowerwords' is not defined"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmedtokens = [ps.stem(word) for word in lowerwords]\n",
    "print(stemmedtokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aed12a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8cd0f9f5f7f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowerwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[index]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp(''.join(lowerwords))\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bffedaa7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-41a36678b659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmas_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "lemmas = [token.lemmas_ for token in doc]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanreviews = ''.join(lemmas)\n",
    "cleanreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "869c11a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemmas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2cb492abafea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreviewscv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lemmas' is not defined"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "reviewscv = cv.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92ca053",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2ddf2f7ebc91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c571a8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d30889339e29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1298\u001b[0m         \"\"\"\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m         return [t for t, i in sorted(self.vocabulary_.items(),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names()[150:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ab85f24",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviewscv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8a671a82bb7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviewscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reviewscv' is not defined"
     ]
    }
   ],
   "source": [
    "print(reviewscv.toarray()[150:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80d7aba6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemmas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-bff39d752ab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcvngramrange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbowmatrixngram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvngramrange\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lemmas' is not defined"
     ]
    }
   ],
   "source": [
    "cvngramrange = CountVectorizer(ngram_range=(1,3),analyzer = 'word',max_features=100)\n",
    "bowmatrixngram = cvngramrange.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b6cad4b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-895c1296d773>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvngramrange\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbowmatrixngram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1298\u001b[0m         \"\"\"\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m         return [t for t, i in sorted(self.vocabulary_.items(),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "print(cvngramrange.get_feature_names())\n",
    "print(bowmatrixngram.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6df8cba6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-759d60fa5903>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidfvngrammaxfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtfidmatrixngram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidfvngrammaxfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TfidVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "tfidfvngrammaxfeatures = TfidVectorizer(ngram_range=(1,3),analyzer = 'word',max_features=500)\n",
    "tfidmatrixngram = tfidfvngrammaxfeatures.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c57ac1d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidfvngrammaxfeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3c287d800ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidfvngrammaxfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidmatrixngram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidfvngrammaxfeatures' is not defined"
     ]
    }
   ],
   "source": [
    "print(tfidfvngrammaxfeatures.get_feature_names())\n",
    "print(tfidmatrixngram.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c35f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(40,30))\n",
    "    plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae637d66",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'set2' is not a valid value for name; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7e84f7267460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pron'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'set2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplot_cloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, font_path, width, height, margin, ranks_only, prefer_horizontal, mask, scale, color_func, max_words, min_font_size, stopwords, random_state, background_color, max_font_size, font_step, mode, relative_scaling, regexp, collocations, colormap, normalize_plurals, contour_width, contour_color, repeat, include_numbers, min_word_length, collocation_threshold)\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontour_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontour_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolor_func\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcolormap_color_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, colormap)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolormap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     def __call__(self, word, font_size, position, orientation,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cm.py\u001b[0m in \u001b[0;36mget_cmap\u001b[1;34m(name, lut)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColormap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m     \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_in_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cmap_registry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlut\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cmap_registry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_check_in_list\u001b[1;34m(_values, **kwargs)\u001b[0m\n\u001b[0;32m   2264\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2266\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   2267\u001b[0m                 \u001b[1;34m\"{!r} is not a valid value for {}; supported values are {}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2268\u001b[0m                 .format(v, k, ', '.join(map(repr, values))))\n",
      "\u001b[1;31mValueError\u001b[0m: 'set2' is not a valid value for name; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'"
     ]
    }
   ],
   "source": [
    "STOPWORDS.add('Pron')\n",
    "wordcloud = WordCloud(width=3000,height=2000,background_color='white',max_words=100,colormap='set2',stopwords=STOPWORDS)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "666b31ee",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3e2396db573e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mone_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdoc_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ent'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "one_block = clean_reviews\n",
    "doc_block = nlp(one_block)\n",
    "spacy.display.render(doc_block,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb724f52",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-819f12caee3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc_block\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_block' is not defined"
     ]
    }
   ],
   "source": [
    "for token in doc_block[100,200]:\n",
    "    print(token,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67b315b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-dc737a91d03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnounverbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc_block\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'NOUN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'VERB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnounverbs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_block' is not defined"
     ]
    }
   ],
   "source": [
    "nounverbs = [token.text for token in doc_block if token.pos_ in ('NOUN','VERB')]\n",
    "print(nounverbs[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01a7783d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-e0a439e7e377>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-e0a439e7e377>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    wordfreq = sorted(wordfreq, key=lambda [x]:x[1],reverse=True)\u001b[0m\n\u001b[1;37m                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(nounverbs)\n",
    "sumwords = x.sum(axis=0)\n",
    "wordfreq = [(word.sumwords[0,idx]) for word, idx in cv.vocabulary_.items()]\n",
    "wordfreq = sorted(wordfreq, key=lambda [x]:x[1],reverse=True)\n",
    "wddf = pd.DataFrame(wordfreq)\n",
    "wddf.columns=['word','count']\n",
    "wddf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a011731d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wddf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3323f2d7ee1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwddf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Top 10 nouns and verbs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wddf' is not defined"
     ]
    }
   ],
   "source": [
    "wddf[0:10].plot.bar(x='word',figsize=(12,8),title='Top 10 nouns and verbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6803527",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a06e347352ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = tokenize.sent_tokenize(''.join(reviews))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de748cf5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5cc22eecf324>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentences'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msentdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf = pd.DataFrame(sentences,columns=['sentences'])\n",
    "sentdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aad0fb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandons</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abducted</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abduction</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>yucky</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>yummy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>zealot</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>zealots</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>zealous</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2477 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  value\n",
       "0       abandon     -2\n",
       "1     abandoned     -2\n",
       "2      abandons     -2\n",
       "3      abducted     -2\n",
       "4     abduction     -2\n",
       "...         ...    ...\n",
       "2472      yucky     -2\n",
       "2473      yummy      3\n",
       "2474     zealot     -2\n",
       "2475    zealots     -2\n",
       "2476    zealous      2\n",
       "\n",
       "[2477 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affin = pd.read_csv('Downloads/Afinn.csv')\n",
    "affin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89e5ed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abandon': -2,\n",
       " 'abandoned': -2,\n",
       " 'abandons': -2,\n",
       " 'abducted': -2,\n",
       " 'abduction': -2,\n",
       " 'abductions': -2,\n",
       " 'abhor': -3,\n",
       " 'abhorred': -3,\n",
       " 'abhorrent': -3,\n",
       " 'abhors': -3,\n",
       " 'abilities': 2,\n",
       " 'ability': 2,\n",
       " 'aboard': 1,\n",
       " 'absentee': -1,\n",
       " 'absentees': -1,\n",
       " 'absolve': 2,\n",
       " 'absolved': 2,\n",
       " 'absolves': 2,\n",
       " 'absolving': 2,\n",
       " 'absorbed': 1,\n",
       " 'abuse': -3,\n",
       " 'abused': -3,\n",
       " 'abuses': -3,\n",
       " 'abusive': -3,\n",
       " 'accept': 1,\n",
       " 'accepted': 1,\n",
       " 'accepting': 1,\n",
       " 'accepts': 1,\n",
       " 'accident': -2,\n",
       " 'accidental': -2,\n",
       " 'accidentally': -2,\n",
       " 'accidents': -2,\n",
       " 'accomplish': 2,\n",
       " 'accomplished': 2,\n",
       " 'accomplishes': 2,\n",
       " 'accusation': -2,\n",
       " 'accusations': -2,\n",
       " 'accuse': -2,\n",
       " 'accused': -2,\n",
       " 'accuses': -2,\n",
       " 'accusing': -2,\n",
       " 'ache': -2,\n",
       " 'achievable': 1,\n",
       " 'aching': -2,\n",
       " 'acquit': 2,\n",
       " 'acquits': 2,\n",
       " 'acquitted': 2,\n",
       " 'acquitting': 2,\n",
       " 'acrimonious': -3,\n",
       " 'active': 1,\n",
       " 'adequate': 1,\n",
       " 'admire': 3,\n",
       " 'admired': 3,\n",
       " 'admires': 3,\n",
       " 'admiring': 3,\n",
       " 'admit': -1,\n",
       " 'admits': -1,\n",
       " 'admitted': -1,\n",
       " 'admonish': -2,\n",
       " 'admonished': -2,\n",
       " 'adopt': 1,\n",
       " 'adopts': 1,\n",
       " 'adorable': 3,\n",
       " 'adore': 3,\n",
       " 'adored': 3,\n",
       " 'adores': 3,\n",
       " 'advanced': 1,\n",
       " 'advantage': 2,\n",
       " 'advantages': 2,\n",
       " 'adventure': 2,\n",
       " 'adventures': 2,\n",
       " 'adventurous': 2,\n",
       " 'affected': -1,\n",
       " 'affection': 3,\n",
       " 'affectionate': 3,\n",
       " 'afflicted': -1,\n",
       " 'affronted': -1,\n",
       " 'afraid': -2,\n",
       " 'aggravate': -2,\n",
       " 'aggravated': -2,\n",
       " 'aggravates': -2,\n",
       " 'aggravating': -2,\n",
       " 'aggression': -2,\n",
       " 'aggressions': -2,\n",
       " 'aggressive': -2,\n",
       " 'aghast': -2,\n",
       " 'agog': 2,\n",
       " 'agonise': -3,\n",
       " 'agonised': -3,\n",
       " 'agonises': -3,\n",
       " 'agonising': -3,\n",
       " 'agonize': -3,\n",
       " 'agonized': -3,\n",
       " 'agonizes': -3,\n",
       " 'agonizing': -3,\n",
       " 'agree': 1,\n",
       " 'agreeable': 2,\n",
       " 'agreed': 1,\n",
       " 'agreement': 1,\n",
       " 'agrees': 1,\n",
       " 'alarm': -2,\n",
       " 'alarmed': -2,\n",
       " 'alarmist': -2,\n",
       " 'alarmists': -2,\n",
       " 'alas': -1,\n",
       " 'alert': -1,\n",
       " 'alienation': -2,\n",
       " 'alive': 1,\n",
       " 'allergic': -2,\n",
       " 'allow': 1,\n",
       " 'alone': -2,\n",
       " 'amaze': 2,\n",
       " 'amazed': 2,\n",
       " 'amazes': 2,\n",
       " 'amazing': 4,\n",
       " 'ambitious': 2,\n",
       " 'ambivalent': -1,\n",
       " 'amuse': 3,\n",
       " 'amused': 3,\n",
       " 'amusement': 3,\n",
       " 'amusements': 3,\n",
       " 'anger': -3,\n",
       " 'angers': -3,\n",
       " 'angry': -3,\n",
       " 'anguish': -3,\n",
       " 'anguished': -3,\n",
       " 'animosity': -2,\n",
       " 'annoy': -2,\n",
       " 'annoyance': -2,\n",
       " 'annoyed': -2,\n",
       " 'annoying': -2,\n",
       " 'annoys': -2,\n",
       " 'antagonistic': -2,\n",
       " 'anti': -1,\n",
       " 'anticipation': 1,\n",
       " 'anxiety': -2,\n",
       " 'anxious': -2,\n",
       " 'apathetic': -3,\n",
       " 'apathy': -3,\n",
       " 'apeshit': -3,\n",
       " 'apocalyptic': -2,\n",
       " 'apologise': -1,\n",
       " 'apologised': -1,\n",
       " 'apologises': -1,\n",
       " 'apologising': -1,\n",
       " 'apologize': -1,\n",
       " 'apologized': -1,\n",
       " 'apologizes': -1,\n",
       " 'apologizing': -1,\n",
       " 'apology': -1,\n",
       " 'appalled': -2,\n",
       " 'appalling': -2,\n",
       " 'appease': 2,\n",
       " 'appeased': 2,\n",
       " 'appeases': 2,\n",
       " 'appeasing': 2,\n",
       " 'applaud': 2,\n",
       " 'applauded': 2,\n",
       " 'applauding': 2,\n",
       " 'applauds': 2,\n",
       " 'applause': 2,\n",
       " 'appreciate': 2,\n",
       " 'appreciated': 2,\n",
       " 'appreciates': 2,\n",
       " 'appreciating': 2,\n",
       " 'appreciation': 2,\n",
       " 'apprehensive': -2,\n",
       " 'approval': 2,\n",
       " 'approved': 2,\n",
       " 'approves': 2,\n",
       " 'ardent': 1,\n",
       " 'arrest': -2,\n",
       " 'arrested': -3,\n",
       " 'arrests': -2,\n",
       " 'arrogant': -2,\n",
       " 'ashame': -2,\n",
       " 'ashamed': -2,\n",
       " 'ass': -4,\n",
       " 'assassination': -3,\n",
       " 'assassinations': -3,\n",
       " 'asset': 2,\n",
       " 'assets': 2,\n",
       " 'assfucking': -4,\n",
       " 'asshole': -4,\n",
       " 'astonished': 2,\n",
       " 'astound': 3,\n",
       " 'astounded': 3,\n",
       " 'astounding': 3,\n",
       " 'astoundingly': 3,\n",
       " 'astounds': 3,\n",
       " 'attack': -1,\n",
       " 'attacked': -1,\n",
       " 'attacking': -1,\n",
       " 'attacks': -1,\n",
       " 'attract': 1,\n",
       " 'attracted': 1,\n",
       " 'attracting': 2,\n",
       " 'attraction': 2,\n",
       " 'attractions': 2,\n",
       " 'attracts': 1,\n",
       " 'audacious': 3,\n",
       " 'authority': 1,\n",
       " 'avert': -1,\n",
       " 'averted': -1,\n",
       " 'averts': -1,\n",
       " 'avid': 2,\n",
       " 'avoid': -1,\n",
       " 'avoided': -1,\n",
       " 'avoids': -1,\n",
       " 'await': -1,\n",
       " 'awaited': -1,\n",
       " 'awaits': -1,\n",
       " 'award': 3,\n",
       " 'awarded': 3,\n",
       " 'awards': 3,\n",
       " 'awesome': 4,\n",
       " 'awful': -3,\n",
       " 'awkward': -2,\n",
       " 'axe': -1,\n",
       " 'axed': -1,\n",
       " 'backed': 1,\n",
       " 'backing': 2,\n",
       " 'backs': 1,\n",
       " 'bad': -3,\n",
       " 'badass': -3,\n",
       " 'badly': -3,\n",
       " 'bailout': -2,\n",
       " 'bamboozle': -2,\n",
       " 'bamboozled': -2,\n",
       " 'bamboozles': -2,\n",
       " 'ban': -2,\n",
       " 'banish': -1,\n",
       " 'bankrupt': -3,\n",
       " 'bankster': -3,\n",
       " 'banned': -2,\n",
       " 'bargain': 2,\n",
       " 'barrier': -2,\n",
       " 'bastard': -5,\n",
       " 'bastards': -5,\n",
       " 'battle': -1,\n",
       " 'battles': -1,\n",
       " 'beaten': -2,\n",
       " 'beatific': 3,\n",
       " 'beating': -1,\n",
       " 'beauties': 3,\n",
       " 'beautiful': 3,\n",
       " 'beautifully': 3,\n",
       " 'beautify': 3,\n",
       " 'belittle': -2,\n",
       " 'belittled': -2,\n",
       " 'beloved': 3,\n",
       " 'benefit': 2,\n",
       " 'benefits': 2,\n",
       " 'benefitted': 2,\n",
       " 'benefitting': 2,\n",
       " 'bereave': -2,\n",
       " 'bereaved': -2,\n",
       " 'bereaves': -2,\n",
       " 'bereaving': -2,\n",
       " 'best': 3,\n",
       " 'betray': -3,\n",
       " 'betrayal': -3,\n",
       " 'betrayed': -3,\n",
       " 'betraying': -3,\n",
       " 'betrays': -3,\n",
       " 'better': 2,\n",
       " 'bias': -1,\n",
       " 'biased': -2,\n",
       " 'big': 1,\n",
       " 'bitch': -5,\n",
       " 'bitches': -5,\n",
       " 'bitter': -2,\n",
       " 'bitterly': -2,\n",
       " 'bizarre': -2,\n",
       " 'blah': -2,\n",
       " 'blame': -2,\n",
       " 'blamed': -2,\n",
       " 'blames': -2,\n",
       " 'blaming': -2,\n",
       " 'bless': 2,\n",
       " 'blesses': 2,\n",
       " 'blessing': 3,\n",
       " 'blind': -1,\n",
       " 'bliss': 3,\n",
       " 'blissful': 3,\n",
       " 'blithe': 2,\n",
       " 'block': -1,\n",
       " 'blockbuster': 3,\n",
       " 'blocked': -1,\n",
       " 'blocking': -1,\n",
       " 'blocks': -1,\n",
       " 'bloody': -3,\n",
       " 'blurry': -2,\n",
       " 'boastful': -2,\n",
       " 'bold': 2,\n",
       " 'boldly': 2,\n",
       " 'bomb': -1,\n",
       " 'boost': 1,\n",
       " 'boosted': 1,\n",
       " 'boosting': 1,\n",
       " 'boosts': 1,\n",
       " 'bore': -2,\n",
       " 'bored': -2,\n",
       " 'boring': -3,\n",
       " 'bother': -2,\n",
       " 'bothered': -2,\n",
       " 'bothers': -2,\n",
       " 'bothersome': -2,\n",
       " 'boycott': -2,\n",
       " 'boycotted': -2,\n",
       " 'boycotting': -2,\n",
       " 'boycotts': -2,\n",
       " 'brainwashing': -3,\n",
       " 'brave': 2,\n",
       " 'breakthrough': 3,\n",
       " 'breathtaking': 5,\n",
       " 'bribe': -3,\n",
       " 'bright': 1,\n",
       " 'brightest': 2,\n",
       " 'brightness': 1,\n",
       " 'brilliant': 4,\n",
       " 'brisk': 2,\n",
       " 'broke': -1,\n",
       " 'broken': -1,\n",
       " 'brooding': -2,\n",
       " 'bullied': -2,\n",
       " 'bullshit': -4,\n",
       " 'bully': -2,\n",
       " 'bullying': -2,\n",
       " 'bummer': -2,\n",
       " 'buoyant': 2,\n",
       " 'burden': -2,\n",
       " 'burdened': -2,\n",
       " 'burdening': -2,\n",
       " 'burdens': -2,\n",
       " 'calm': 2,\n",
       " 'calmed': 2,\n",
       " 'calming': 2,\n",
       " 'calms': 2,\n",
       " \"can't stand\": -3,\n",
       " 'cancel': -1,\n",
       " 'cancelled': -1,\n",
       " 'cancelling': -1,\n",
       " 'cancels': -1,\n",
       " 'cancer': -1,\n",
       " 'capable': 1,\n",
       " 'captivated': 3,\n",
       " 'care': 2,\n",
       " 'carefree': 1,\n",
       " 'careful': 2,\n",
       " 'carefully': 2,\n",
       " 'careless': -2,\n",
       " 'cares': 2,\n",
       " 'cashing in': -2,\n",
       " 'casualty': -2,\n",
       " 'catastrophe': -3,\n",
       " 'catastrophic': -4,\n",
       " 'cautious': -1,\n",
       " 'celebrate': 3,\n",
       " 'celebrated': 3,\n",
       " 'celebrates': 3,\n",
       " 'celebrating': 3,\n",
       " 'censor': -2,\n",
       " 'censored': -2,\n",
       " 'censors': -2,\n",
       " 'certain': 1,\n",
       " 'chagrin': -2,\n",
       " 'chagrined': -2,\n",
       " 'challenge': -1,\n",
       " 'chance': 2,\n",
       " 'chances': 2,\n",
       " 'chaos': -2,\n",
       " 'chaotic': -2,\n",
       " 'charged': -3,\n",
       " 'charges': -2,\n",
       " 'charm': 3,\n",
       " 'charming': 3,\n",
       " 'charmless': -3,\n",
       " 'chastise': -3,\n",
       " 'chastised': -3,\n",
       " 'chastises': -3,\n",
       " 'chastising': -3,\n",
       " 'cheat': -3,\n",
       " 'cheated': -3,\n",
       " 'cheater': -3,\n",
       " 'cheaters': -3,\n",
       " 'cheats': -3,\n",
       " 'cheer': 2,\n",
       " 'cheered': 2,\n",
       " 'cheerful': 2,\n",
       " 'cheering': 2,\n",
       " 'cheerless': -2,\n",
       " 'cheers': 2,\n",
       " 'cheery': 3,\n",
       " 'cherish': 2,\n",
       " 'cherished': 2,\n",
       " 'cherishes': 2,\n",
       " 'cherishing': 2,\n",
       " 'chic': 2,\n",
       " 'childish': -2,\n",
       " 'chilling': -1,\n",
       " 'choke': -2,\n",
       " 'choked': -2,\n",
       " 'chokes': -2,\n",
       " 'choking': -2,\n",
       " 'clarifies': 2,\n",
       " 'clarity': 2,\n",
       " 'clash': -2,\n",
       " 'classy': 3,\n",
       " 'clean': 2,\n",
       " 'cleaner': 2,\n",
       " 'clear': 1,\n",
       " 'cleared': 1,\n",
       " 'clearly': 1,\n",
       " 'clears': 1,\n",
       " 'clever': 2,\n",
       " 'clouded': -1,\n",
       " 'clueless': -2,\n",
       " 'cock': -5,\n",
       " 'cocksucker': -5,\n",
       " 'cocksuckers': -5,\n",
       " 'cocky': -2,\n",
       " 'coerced': -2,\n",
       " 'collapse': -2,\n",
       " 'collapsed': -2,\n",
       " 'collapses': -2,\n",
       " 'collapsing': -2,\n",
       " 'collide': -1,\n",
       " 'collides': -1,\n",
       " 'colliding': -1,\n",
       " 'collision': -2,\n",
       " 'collisions': -2,\n",
       " 'colluding': -3,\n",
       " 'combat': -1,\n",
       " 'combats': -1,\n",
       " 'comedy': 1,\n",
       " 'comfort': 2,\n",
       " 'comfortable': 2,\n",
       " 'comforting': 2,\n",
       " 'comforts': 2,\n",
       " 'commend': 2,\n",
       " 'commended': 2,\n",
       " 'commit': 1,\n",
       " 'commitment': 2,\n",
       " 'commits': 1,\n",
       " 'committed': 1,\n",
       " 'committing': 1,\n",
       " 'compassionate': 2,\n",
       " 'compelled': 1,\n",
       " 'competent': 2,\n",
       " 'competitive': 2,\n",
       " 'complacent': -2,\n",
       " 'complain': -2,\n",
       " 'complained': -2,\n",
       " 'complains': -2,\n",
       " 'comprehensive': 2,\n",
       " 'conciliate': 2,\n",
       " 'conciliated': 2,\n",
       " 'conciliates': 2,\n",
       " 'conciliating': 2,\n",
       " 'condemn': -2,\n",
       " 'condemnation': -2,\n",
       " 'condemned': -2,\n",
       " 'condemns': -2,\n",
       " 'confidence': 2,\n",
       " 'confident': 2,\n",
       " 'conflict': -2,\n",
       " 'conflicting': -2,\n",
       " 'conflictive': -2,\n",
       " 'conflicts': -2,\n",
       " 'confuse': -2,\n",
       " 'confused': -2,\n",
       " 'confusing': -2,\n",
       " 'congrats': 2,\n",
       " 'congratulate': 2,\n",
       " 'congratulation': 2,\n",
       " 'congratulations': 2,\n",
       " 'consent': 2,\n",
       " 'consents': 2,\n",
       " 'consolable': 2,\n",
       " 'conspiracy': -3,\n",
       " 'constrained': -2,\n",
       " 'contagion': -2,\n",
       " 'contagions': -2,\n",
       " 'contagious': -1,\n",
       " 'contempt': -2,\n",
       " 'contemptuous': -2,\n",
       " 'contemptuously': -2,\n",
       " 'contend': -1,\n",
       " 'contender': -1,\n",
       " 'contending': -1,\n",
       " 'contentious': -2,\n",
       " 'contestable': -2,\n",
       " 'controversial': -2,\n",
       " 'controversially': -2,\n",
       " 'convince': 1,\n",
       " 'convinced': 1,\n",
       " 'convinces': 1,\n",
       " 'convivial': 2,\n",
       " 'cool': 1,\n",
       " 'cool stuff': 3,\n",
       " 'cornered': -2,\n",
       " 'corpse': -1,\n",
       " 'costly': -2,\n",
       " 'courage': 2,\n",
       " 'courageous': 2,\n",
       " 'courteous': 2,\n",
       " 'courtesy': 2,\n",
       " 'cover-up': -3,\n",
       " 'coward': -2,\n",
       " 'cowardly': -2,\n",
       " 'coziness': 2,\n",
       " 'cramp': -1,\n",
       " 'crap': -3,\n",
       " 'crash': -2,\n",
       " 'crazier': -2,\n",
       " 'craziest': -2,\n",
       " 'crazy': -2,\n",
       " 'creative': 2,\n",
       " 'crestfallen': -2,\n",
       " 'cried': -2,\n",
       " 'cries': -2,\n",
       " 'crime': -3,\n",
       " 'criminal': -3,\n",
       " 'criminals': -3,\n",
       " 'crisis': -3,\n",
       " 'critic': -2,\n",
       " 'criticism': -2,\n",
       " 'criticize': -2,\n",
       " 'criticized': -2,\n",
       " 'criticizes': -2,\n",
       " 'criticizing': -2,\n",
       " 'critics': -2,\n",
       " 'cruel': -3,\n",
       " 'cruelty': -3,\n",
       " 'crush': -1,\n",
       " 'crushed': -2,\n",
       " 'crushes': -1,\n",
       " 'crushing': -1,\n",
       " 'cry': -1,\n",
       " 'crying': -2,\n",
       " 'cunt': -5,\n",
       " 'curious': 1,\n",
       " 'curse': -1,\n",
       " 'cut': -1,\n",
       " 'cute': 2,\n",
       " 'cuts': -1,\n",
       " 'cutting': -1,\n",
       " 'cynic': -2,\n",
       " 'cynical': -2,\n",
       " 'cynicism': -2,\n",
       " 'damage': -3,\n",
       " 'damages': -3,\n",
       " 'damn': -4,\n",
       " 'damned': -4,\n",
       " 'damnit': -4,\n",
       " 'danger': -2,\n",
       " 'daredevil': 2,\n",
       " 'daring': 2,\n",
       " 'darkest': -2,\n",
       " 'darkness': -1,\n",
       " 'dauntless': 2,\n",
       " 'dead': -3,\n",
       " 'deadlock': -2,\n",
       " 'deafening': -1,\n",
       " 'dear': 2,\n",
       " 'dearly': 3,\n",
       " 'death': -2,\n",
       " 'debonair': 2,\n",
       " 'debt': -2,\n",
       " 'deceit': -3,\n",
       " 'deceitful': -3,\n",
       " 'deceive': -3,\n",
       " 'deceived': -3,\n",
       " 'deceives': -3,\n",
       " 'deceiving': -3,\n",
       " 'deception': -3,\n",
       " 'decisive': 1,\n",
       " 'dedicated': 2,\n",
       " 'defeated': -2,\n",
       " 'defect': -3,\n",
       " 'defects': -3,\n",
       " 'defender': 2,\n",
       " 'defenders': 2,\n",
       " 'defenseless': -2,\n",
       " 'defer': -1,\n",
       " 'deferring': -1,\n",
       " 'defiant': -1,\n",
       " 'deficit': -2,\n",
       " 'degrade': -2,\n",
       " 'degraded': -2,\n",
       " 'degrades': -2,\n",
       " 'dehumanize': -2,\n",
       " 'dehumanized': -2,\n",
       " 'dehumanizes': -2,\n",
       " 'dehumanizing': -2,\n",
       " 'deject': -2,\n",
       " 'dejected': -2,\n",
       " 'dejecting': -2,\n",
       " 'dejects': -2,\n",
       " 'delay': -1,\n",
       " 'delayed': -1,\n",
       " 'delight': 3,\n",
       " 'delighted': 3,\n",
       " 'delighting': 3,\n",
       " 'delights': 3,\n",
       " 'demand': -1,\n",
       " 'demanded': -1,\n",
       " 'demanding': -1,\n",
       " 'demands': -1,\n",
       " 'demonstration': -1,\n",
       " 'demoralized': -2,\n",
       " 'denied': -2,\n",
       " 'denier': -2,\n",
       " 'deniers': -2,\n",
       " 'denies': -2,\n",
       " 'denounce': -2,\n",
       " 'denounces': -2,\n",
       " 'deny': -2,\n",
       " 'denying': -2,\n",
       " 'depressed': -2,\n",
       " 'depressing': -2,\n",
       " 'derail': -2,\n",
       " 'derailed': -2,\n",
       " 'derails': -2,\n",
       " 'deride': -2,\n",
       " 'derided': -2,\n",
       " 'derides': -2,\n",
       " 'deriding': -2,\n",
       " 'derision': -2,\n",
       " 'desirable': 2,\n",
       " 'desire': 1,\n",
       " 'desired': 2,\n",
       " 'desirous': 2,\n",
       " 'despair': -3,\n",
       " 'despairing': -3,\n",
       " 'despairs': -3,\n",
       " 'desperate': -3,\n",
       " 'desperately': -3,\n",
       " 'despondent': -3,\n",
       " 'destroy': -3,\n",
       " 'destroyed': -3,\n",
       " 'destroying': -3,\n",
       " 'destroys': -3,\n",
       " 'destruction': -3,\n",
       " 'destructive': -3,\n",
       " 'detached': -1,\n",
       " 'detain': -2,\n",
       " 'detained': -2,\n",
       " 'detention': -2,\n",
       " 'determined': 2,\n",
       " 'devastate': -2,\n",
       " 'devastated': -2,\n",
       " 'devastating': -2,\n",
       " 'devoted': 3,\n",
       " 'diamond': 1,\n",
       " 'dick': -4,\n",
       " 'dickhead': -4,\n",
       " 'die': -3,\n",
       " 'died': -3,\n",
       " 'difficult': -1,\n",
       " 'diffident': -2,\n",
       " 'dilemma': -1,\n",
       " 'dipshit': -3,\n",
       " 'dire': -3,\n",
       " 'direful': -3,\n",
       " 'dirt': -2,\n",
       " 'dirtier': -2,\n",
       " 'dirtiest': -2,\n",
       " 'dirty': -2,\n",
       " 'disabling': -1,\n",
       " 'disadvantage': -2,\n",
       " 'disadvantaged': -2,\n",
       " 'disappear': -1,\n",
       " 'disappeared': -1,\n",
       " 'disappears': -1,\n",
       " 'disappoint': -2,\n",
       " 'disappointed': -2,\n",
       " 'disappointing': -2,\n",
       " 'disappointment': -2,\n",
       " 'disappointments': -2,\n",
       " 'disappoints': -2,\n",
       " 'disaster': -2,\n",
       " 'disasters': -2,\n",
       " 'disastrous': -3,\n",
       " 'disbelieve': -2,\n",
       " 'discard': -1,\n",
       " 'discarded': -1,\n",
       " 'discarding': -1,\n",
       " 'discards': -1,\n",
       " 'disconsolate': -2,\n",
       " 'disconsolation': -2,\n",
       " 'discontented': -2,\n",
       " 'discord': -2,\n",
       " 'discounted': -1,\n",
       " 'discouraged': -2,\n",
       " 'discredited': -2,\n",
       " 'disdain': -2,\n",
       " 'disgrace': -2,\n",
       " 'disgraced': -2,\n",
       " 'disguise': -1,\n",
       " 'disguised': -1,\n",
       " 'disguises': -1,\n",
       " 'disguising': -1,\n",
       " 'disgust': -3,\n",
       " 'disgusted': -3,\n",
       " 'disgusting': -3,\n",
       " 'disheartened': -2,\n",
       " 'dishonest': -2,\n",
       " 'disillusioned': -2,\n",
       " 'disinclined': -2,\n",
       " 'disjointed': -2,\n",
       " 'dislike': -2,\n",
       " 'dismal': -2,\n",
       " 'dismayed': -2,\n",
       " 'disorder': -2,\n",
       " 'disorganized': -2,\n",
       " 'disoriented': -2,\n",
       " 'disparage': -2,\n",
       " 'disparaged': -2,\n",
       " 'disparages': -2,\n",
       " 'disparaging': -2,\n",
       " 'displeased': -2,\n",
       " 'dispute': -2,\n",
       " 'disputed': -2,\n",
       " 'disputes': -2,\n",
       " 'disputing': -2,\n",
       " 'disqualified': -2,\n",
       " 'disquiet': -2,\n",
       " 'disregard': -2,\n",
       " 'disregarded': -2,\n",
       " 'disregarding': -2,\n",
       " 'disregards': -2,\n",
       " 'disrespect': -2,\n",
       " 'disrespected': -2,\n",
       " 'disruption': -2,\n",
       " 'disruptions': -2,\n",
       " 'disruptive': -2,\n",
       " 'dissatisfied': -2,\n",
       " 'distort': -2,\n",
       " 'distorted': -2,\n",
       " 'distorting': -2,\n",
       " 'distorts': -2,\n",
       " 'distract': -2,\n",
       " 'distracted': -2,\n",
       " 'distraction': -2,\n",
       " 'distracts': -2,\n",
       " 'distress': -2,\n",
       " 'distressed': -2,\n",
       " 'distresses': -2,\n",
       " 'distressing': -2,\n",
       " 'distrust': -3,\n",
       " 'distrustful': -3,\n",
       " 'disturb': -2,\n",
       " 'disturbed': -2,\n",
       " 'disturbing': -2,\n",
       " 'disturbs': -2,\n",
       " 'dithering': -2,\n",
       " 'dizzy': -1,\n",
       " 'dodging': -2,\n",
       " 'dodgy': -2,\n",
       " 'does not work': -3,\n",
       " 'dolorous': -2,\n",
       " 'dont like': -2,\n",
       " 'doom': -2,\n",
       " 'doomed': -2,\n",
       " 'doubt': -1,\n",
       " 'doubted': -1,\n",
       " 'doubtful': -1,\n",
       " 'doubting': -1,\n",
       " 'doubts': -1,\n",
       " 'douche': -3,\n",
       " 'douchebag': -3,\n",
       " 'downcast': -2,\n",
       " 'downhearted': -2,\n",
       " 'downside': -2,\n",
       " 'drag': -1,\n",
       " 'dragged': -1,\n",
       " 'drags': -1,\n",
       " 'drained': -2,\n",
       " 'dread': -2,\n",
       " 'dreaded': -2,\n",
       " 'dreadful': -3,\n",
       " 'dreading': -2,\n",
       " 'dream': 1,\n",
       " 'dreams': 1,\n",
       " 'dreary': -2,\n",
       " 'droopy': -2,\n",
       " 'drop': -1,\n",
       " 'drown': -2,\n",
       " 'drowned': -2,\n",
       " 'drowns': -2,\n",
       " 'drunk': -2,\n",
       " 'dubious': -2,\n",
       " 'dud': -2,\n",
       " 'dull': -2,\n",
       " 'dumb': -3,\n",
       " 'dumbass': -3,\n",
       " 'dump': -1,\n",
       " 'dumped': -2,\n",
       " 'dumps': -1,\n",
       " 'dupe': -2,\n",
       " 'duped': -2,\n",
       " 'dysfunction': -2,\n",
       " 'eager': 2,\n",
       " 'earnest': 2,\n",
       " 'ease': 2,\n",
       " 'easy': 1,\n",
       " 'ecstatic': 4,\n",
       " 'eerie': -2,\n",
       " 'eery': -2,\n",
       " 'effective': 2,\n",
       " 'effectively': 2,\n",
       " 'elated': 3,\n",
       " 'elation': 3,\n",
       " 'elegant': 2,\n",
       " 'elegantly': 2,\n",
       " 'embarrass': -2,\n",
       " 'embarrassed': -2,\n",
       " 'embarrasses': -2,\n",
       " 'embarrassing': -2,\n",
       " 'embarrassment': -2,\n",
       " 'embittered': -2,\n",
       " 'embrace': 1,\n",
       " 'emergency': -2,\n",
       " 'empathetic': 2,\n",
       " 'emptiness': -1,\n",
       " 'empty': -1,\n",
       " 'enchanted': 2,\n",
       " 'encourage': 2,\n",
       " 'encouraged': 2,\n",
       " 'encouragement': 2,\n",
       " 'encourages': 2,\n",
       " 'endorse': 2,\n",
       " 'endorsed': 2,\n",
       " 'endorsement': 2,\n",
       " 'endorses': 2,\n",
       " 'enemies': -2,\n",
       " 'enemy': -2,\n",
       " 'energetic': 2,\n",
       " 'engage': 1,\n",
       " 'engages': 1,\n",
       " 'engrossed': 1,\n",
       " 'enjoy': 2,\n",
       " 'enjoying': 2,\n",
       " 'enjoys': 2,\n",
       " 'enlighten': 2,\n",
       " 'enlightened': 2,\n",
       " 'enlightening': 2,\n",
       " 'enlightens': 2,\n",
       " 'ennui': -2,\n",
       " 'enrage': -2,\n",
       " 'enraged': -2,\n",
       " 'enrages': -2,\n",
       " 'enraging': -2,\n",
       " 'enrapture': 3,\n",
       " 'enslave': -2,\n",
       " 'enslaved': -2,\n",
       " 'enslaves': -2,\n",
       " 'ensure': 1,\n",
       " 'ensuring': 1,\n",
       " 'enterprising': 1,\n",
       " 'entertaining': 2,\n",
       " 'enthral': 3,\n",
       " 'enthusiastic': 3,\n",
       " 'entitled': 1,\n",
       " 'entrusted': 2,\n",
       " 'envies': -1,\n",
       " 'envious': -2,\n",
       " 'envy': -1,\n",
       " 'envying': -1,\n",
       " 'erroneous': -2,\n",
       " 'error': -2,\n",
       " 'errors': -2,\n",
       " 'escape': -1,\n",
       " 'escapes': -1,\n",
       " 'escaping': -1,\n",
       " 'esteemed': 2,\n",
       " 'ethical': 2,\n",
       " 'euphoria': 3,\n",
       " 'euphoric': 4,\n",
       " 'eviction': -1,\n",
       " 'evil': -3,\n",
       " 'exaggerate': -2,\n",
       " 'exaggerated': -2,\n",
       " 'exaggerates': -2,\n",
       " 'exaggerating': -2,\n",
       " 'exasperated': 2,\n",
       " 'excellence': 3,\n",
       " 'excellent': 3,\n",
       " 'excite': 3,\n",
       " 'excited': 3,\n",
       " 'excitement': 3,\n",
       " 'exciting': 3,\n",
       " 'exclude': -1,\n",
       " 'excluded': -2,\n",
       " 'exclusion': -1,\n",
       " 'exclusive': 2,\n",
       " 'excuse': -1,\n",
       " 'exempt': -1,\n",
       " 'exhausted': -2,\n",
       " 'exhilarated': 3,\n",
       " 'exhilarates': 3,\n",
       " 'exhilarating': 3,\n",
       " 'exonerate': 2,\n",
       " 'exonerated': 2,\n",
       " 'exonerates': 2,\n",
       " 'exonerating': 2,\n",
       " 'expand': 1,\n",
       " 'expands': 1,\n",
       " 'expel': -2,\n",
       " 'expelled': -2,\n",
       " 'expelling': -2,\n",
       " 'expels': -2,\n",
       " 'exploit': -2,\n",
       " 'exploited': -2,\n",
       " 'exploiting': -2,\n",
       " 'exploits': -2,\n",
       " 'exploration': 1,\n",
       " 'explorations': 1,\n",
       " 'expose': -1,\n",
       " 'exposed': -1,\n",
       " 'exposes': -1,\n",
       " 'exposing': -1,\n",
       " 'extend': 1,\n",
       " 'extends': 1,\n",
       " 'exuberant': 4,\n",
       " 'exultant': 3,\n",
       " 'exultantly': 3,\n",
       " 'fabulous': 4,\n",
       " 'fad': -2,\n",
       " 'fag': -3,\n",
       " 'faggot': -3,\n",
       " 'faggots': -3,\n",
       " 'fail': -2,\n",
       " 'failed': -2,\n",
       " 'failing': -2,\n",
       " 'fails': -2,\n",
       " 'failure': -2,\n",
       " 'failures': -2,\n",
       " 'fainthearted': -2,\n",
       " 'fair': 2,\n",
       " 'faith': 1,\n",
       " 'faithful': 3,\n",
       " 'fake': -3,\n",
       " 'fakes': -3,\n",
       " 'faking': -3,\n",
       " 'fallen': -2,\n",
       " 'falling': -1,\n",
       " 'falsified': -3,\n",
       " 'falsify': -3,\n",
       " 'fame': 1,\n",
       " 'fan': 3,\n",
       " 'fantastic': 4,\n",
       " 'farce': -1,\n",
       " 'fascinate': 3,\n",
       " 'fascinated': 3,\n",
       " 'fascinates': 3,\n",
       " 'fascinating': 3,\n",
       " 'fascist': -2,\n",
       " 'fascists': -2,\n",
       " 'fatalities': -3,\n",
       " 'fatality': -3,\n",
       " 'fatigue': -2,\n",
       " 'fatigued': -2,\n",
       " 'fatigues': -2,\n",
       " 'fatiguing': -2,\n",
       " 'favor': 2,\n",
       " 'favored': 2,\n",
       " 'favorite': 2,\n",
       " 'favorited': 2,\n",
       " 'favorites': 2,\n",
       " 'favors': 2,\n",
       " 'fear': -2,\n",
       " 'fearful': -2,\n",
       " 'fearing': -2,\n",
       " 'fearless': 2,\n",
       " 'fearsome': -2,\n",
       " 'fed up': -3,\n",
       " 'feeble': -2,\n",
       " 'feeling': 1,\n",
       " 'felonies': -3,\n",
       " 'felony': -3,\n",
       " 'fervent': 2,\n",
       " 'fervid': 2,\n",
       " 'festive': 2,\n",
       " 'fiasco': -3,\n",
       " 'fidgety': -2,\n",
       " 'fight': -1,\n",
       " 'fine': 2,\n",
       " 'fire': -2,\n",
       " 'fired': -2,\n",
       " 'firing': -2,\n",
       " 'fit': 1,\n",
       " 'fitness': 1,\n",
       " 'flagship': 2,\n",
       " 'flees': -1,\n",
       " 'flop': -2,\n",
       " 'flops': -2,\n",
       " 'flu': -2,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affinityscores = affin.set_index('word')['value'].to_dict()\n",
    "affinityscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1429ac87",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-ce56a9126ce7>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-ce56a9126ce7>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    sentscore+= sentimentlexicon.get(word.lemma_.0)\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sentimentlexicon = affinityscores\n",
    "def calculate_sentiment(text:str=None):\n",
    "    sentscore=0\n",
    "    if text:\n",
    "        sentence = nlp(text)\n",
    "        for word in sentence:\n",
    "            sentscore+= sentimentlexicon.get(word.lemma_.0)\n",
    "            return sentscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74318327",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a58abffd3dd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalculate_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'good service'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'calculate_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "calculate_sentiment(text='good service')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ac332cc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-535eb96561e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalculate_sentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentdf' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf['sentiment_value']=sentdf['sentence'].apply(calculate_sentiment)\n",
    "sentdf['sentiment_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70942a68",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-a796eb32b00b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentdf' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf['word_count']=sentdf['sentence'].str.split().apply(len)\n",
    "sentdf['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c60ea971",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c65ec883c4af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentdf' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf.sort_values(by='sentiment_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8ecf238",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-1b56ef3c28c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentdf' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf['sentiment_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec4fab83",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d76244a0ce37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentdf' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf[sentdf['sentiment_value']<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72e08540",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2f7bc0a5ac57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentdf' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf[sentdf['sentiment_value']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d45488c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-3a9ccc93f556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msentdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentdf' is not defined"
     ]
    }
   ],
   "source": [
    "sentdf['index']=range(0,len(sentdf))\n",
    "sentdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2dacfab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c4976de68952>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.distplot(sentdf['sentiment_value'])\n",
    "plt.figure(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f827bc80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-98bf25603b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sentiment_value'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lineplot(y='sentiment_value',x='index',data=sentdf)\n",
    "plt.figure(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a84f18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
